{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JM8Yfnas_Ih8"
      },
      "outputs": [],
      "source": [
        "# LangChain Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## What are Tools in LangChain?\n",
        "\"\"\"\n",
        "A **Tool** is a function you wrap so that the LLM (language model) can call it when needed.\n",
        "\n",
        "**Think of a tool as a helper function the AI can use.**\n",
        "\n",
        "### Why Tools?\n",
        "\n",
        "LLMs are good at language but weak at:\n",
        "- Math\n",
        "- Web search\n",
        "- APIs\n",
        "- Database lookup\n",
        "\n",
        "Tools fix this!\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "nlo6kubY_T1A",
        "outputId": "a5bfb83c-e58f-472e-dd17-468a0b83e9a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nA **Tool** is a function you wrap so that the LLM (language model) can call it when needed.\\n\\n**Think of a tool as a helper function the AI can use.**\\n\\n### Why Tools?\\n\\nLLMs are good at language but weak at:\\n- Math\\n- Web search\\n- APIs\\n- Database lookup\\n\\nTools fix this!\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Import Tool class\n",
        "from langchain.agents import Tool\n"
      ],
      "metadata": {
        "id": "i_ie_7rm_jQ6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Define a basic calculator function\n",
        "def simple_calculator(query: str) -> str:\n",
        "    try:\n",
        "        result = eval(query)  #\n",
        "        return f\"The result is: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "UsKzzIbq_qSo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Wrap it into a LangChain Tool\n",
        "calculator_tool = Tool(\n",
        "    name=\"Calculator\",\n",
        "    func=simple_calculator,\n",
        "    description=\"Useful for doing math calculations. Input should be a valid math expression.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "v8nelV5o_sJg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4 & 5: Create the Agent with the Tool and Initialize"
      ],
      "metadata": {
        "id": "u96oxYRO_yR1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhzg46RoA8pW",
        "outputId": "5da918c4-a656-435f-c2ee-f14787fc811e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "\n",
        "\n",
        "# Set your OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# STEP 4: Create the LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# STEP 5: Initialize the agent with the tool\n",
        "agent = initialize_agent(\n",
        "    tools=[calculator_tool],            # list of Tool objects\n",
        "    llm=llm,                             # your LLM\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,   # type of agent\n",
        "    verbose=True                        # prints reasoning steps\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uIl0NwuAyQH",
        "outputId": "42657093-0ef1-44eb-ad71-d3b1147c26ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3075810662.py:19: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Run the Agent (Tool Calling)"
      ],
      "metadata": {
        "id": "M95yL6TsBJz6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Ask a question that requires the tool\n",
        "response = agent.run(\"What is (12 * 4) + 7?\")\n",
        "print(\"Agent Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4pSleTxBd2N",
        "outputId": "a5f1be7f-6874-4d95-dd73-8556230ce86f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-49192643.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = agent.run(\"What is (12 * 4) + 7?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Calculator` with `(12 * 4) + 7`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mThe result is: 55\u001b[0m\u001b[32;1m\u001b[1;3mThe result of (12 * 4) + 7 is 55.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent Response: The result of (12 * 4) + 7 is 55.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End of the Notebook\n"
      ],
      "metadata": {
        "id": "6js2JlXVBgjy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - Words Meaning Tool"
      ],
      "metadata": {
        "id": "bEzu2FZkB1Os"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 0: Install required packages (if running in Colab)\n",
        "!pip install -q langchain langchain-openai\n",
        "\n",
        "# ✅ STEP 1: Imports and OpenAI API Key Setup\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "import os\n",
        "\n",
        "# Use this if running in Google Colab with secrets stored\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "except:\n",
        "    # If not in Colab, manually set your key below\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"\n",
        "\n",
        "# ✅ STEP 2: Define the dictionary function\n",
        "def get_definition(word: str) -> str:\n",
        "    dictionary = {\n",
        "        \"ai\": \"AI stands for Artificial Intelligence. It refers to the simulation of human intelligence in machines.\",\n",
        "        \"genai\": \"GenAI stands for Generative AI. It can generate text, images, or other content.\",\n",
        "        \"python\": \"Python is a high-level, interpreted programming language known for its simplicity.\",\n",
        "        \"data\": \"Data is a collection of facts, such as numbers, words, measurements, or observations.\",\n",
        "        \"model\": \"In AI, a model is a mathematical representation trained to make predictions or decisions.\"\n",
        "    }\n",
        "\n",
        "    word_lower = word.lower()\n",
        "    return dictionary.get(word_lower, f\"Sorry, I don't have a definition for '{word}' right now.\")\n",
        "\n",
        "# ✅ STEP 3: Wrap the function into a LangChain Tool (NO SPACES in name!)\n",
        "dictionary_tool = Tool(\n",
        "    name=\"dictionary_tool\",  # ✅ Fixed: no spaces or special chars\n",
        "    func=get_definition,\n",
        "    description=\"Useful for finding simple definitions of tech terms. Input should be a single word like 'AI' or 'Python'.\"\n",
        ")\n",
        "\n",
        "# ✅ STEP 4: Initialize LLM and Agent\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=[dictionary_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# ✅ STEP 5: Ask a question and get response\n",
        "query = \"What is cricket?\"\n",
        "response = agent.run(query)\n",
        "print(\"\\n💬 Agent response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCgiBVPZC-Qy",
        "outputId": "4d0c7025-2aa5-4c37-d9a4-7e6bc62a8226"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `dictionary_tool` with `cricket`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mSorry, I don't have a definition for 'cricket' right now.\u001b[0m\u001b[32;1m\u001b[1;3mCricket is a popular sport played between two teams, usually of eleven players each. It involves batting, bowling, and fielding, with the main objective of scoring runs. The game is played on a large oval-shaped field with a rectangular 22-yard pitch at the center. It is especially popular in countries like India, England, Australia, and Pakistan.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "💬 Agent response: Cricket is a popular sport played between two teams, usually of eleven players each. It involves batting, bowling, and fielding, with the main objective of scoring runs. The game is played on a large oval-shaped field with a rectangular 22-yard pitch at the center. It is especially popular in countries like India, England, Australia, and Pakistan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example - Weather Agent with User Input"
      ],
      "metadata": {
        "id": "I-7SyFJeC--9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install dependencies\n",
        "!pip install -q langchain langchain-openai requests\n",
        "\n",
        "# STEP 2: Imports and API Key\n",
        "import os\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# STEP 3: Set your OpenAI API key from userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")  # 🔐 Secure API Key\n",
        "\n",
        "# STEP 4: Define the Weather API tool function\n",
        "def get_weather(city: str) -> str:\n",
        "    try:\n",
        "        geo_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\"\n",
        "        geo_response = requests.get(geo_url).json()\n",
        "        if \"results\" not in geo_response:\n",
        "            return f\"City '{city}' not found.\"\n",
        "\n",
        "        lat = geo_response[\"results\"][0][\"latitude\"]\n",
        "        lon = geo_response[\"results\"][0][\"longitude\"]\n",
        "\n",
        "        weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
        "        weather_response = requests.get(weather_url).json()\n",
        "        weather = weather_response[\"current_weather\"]\n",
        "        return f\"The temperature in {city} is {weather['temperature']}°C with wind speed {weather['windspeed']} km/h.\"\n",
        "    except Exception as e:\n",
        "        return f\"Failed to fetch weather: {str(e)}\"\n",
        "\n",
        "# STEP 5: Wrap in a LangChain Tool\n",
        "weather_tool = Tool(\n",
        "    name=\"weather_tool\",\n",
        "    func=get_weather,\n",
        "    description=\"Fetch current weather for a given city. Input should be a city name.\"\n",
        ")\n",
        "\n",
        "# STEP 6: Initialize the Agent\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
        "agent = initialize_agent(\n",
        "    tools=[weather_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# STEP 7: Get user input\n",
        "city = input(\"Enter city name for weather info: \").strip()\n",
        "response = agent.run(f\"What’s the weather in {city}?\")\n",
        "print(\"\\n💬 Agent response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIkfETT_FbGh",
        "outputId": "6855b77b-ae65-4b78-a59d-b23dcc9ee89d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter city name for weather info: Mumbai\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `weather_tool` with `Mumbai`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mThe temperature in Mumbai is 28.2°C with wind speed 8.4 km/h.\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in Mumbai is 28.2°C with a wind speed of 8.4 km/h.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "💬 Agent response: The current weather in Mumbai is 28.2°C with a wind speed of 8.4 km/h.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example - Weather Agent with User Input for any city in the world along with current time in IST"
      ],
      "metadata": {
        "id": "hIDQIdidFqrp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install dependencies\n",
        "!pip install -q langchain langchain-openai requests pytz\n",
        "\n",
        "# STEP 2: Imports and API Key\n",
        "import os\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from google.colab import userdata\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# STEP 3: Set OpenAI API Key securely\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")  # 🔐\n",
        "\n",
        "# STEP 4: Define the main tool function\n",
        "def get_weather_and_time(city: str) -> str:\n",
        "    try:\n",
        "        # Geocoding API to get lat/lon\n",
        "        geo_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\"\n",
        "        geo_response = requests.get(geo_url).json()\n",
        "\n",
        "        if \"results\" not in geo_response:\n",
        "            return f\"City '{city}' not found.\"\n",
        "\n",
        "        lat = geo_response[\"results\"][0][\"latitude\"]\n",
        "        lon = geo_response[\"results\"][0][\"longitude\"]\n",
        "        name = geo_response[\"results\"][0][\"name\"]\n",
        "        country = geo_response[\"results\"][0].get(\"country\", \"\")\n",
        "\n",
        "        # Weather API\n",
        "        weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
        "        weather_response = requests.get(weather_url).json()\n",
        "        weather = weather_response[\"current_weather\"]\n",
        "        temp = weather[\"temperature\"]\n",
        "        wind = weather[\"windspeed\"]\n",
        "\n",
        "        # IST time\n",
        "        ist_time = datetime.now(pytz.timezone(\"Asia/Kolkata\")).strftime(\"%I:%M %p\")\n",
        "\n",
        "        return (f\"📍 {name}, {country}\\n\"\n",
        "                f\"🌡️ Temperature: {temp}°C\\n\"\n",
        "                f\"💨 Wind Speed: {wind} km/h\\n\"\n",
        "                f\"🕒 Current IST Time: {ist_time}\")\n",
        "    except Exception as e:\n",
        "        return f\"Failed to fetch info: {str(e)}\"\n",
        "\n",
        "# STEP 5: Wrap the function in a LangChain Tool\n",
        "weather_time_tool = Tool(\n",
        "    name=\"weather_time_tool\",\n",
        "    func=get_weather_and_time,\n",
        "    description=\"Provides current weather and IST time for a given city. Input should be a city name.\"\n",
        ")\n",
        "\n",
        "# STEP 6: Initialize LangChain Agent\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
        "agent = initialize_agent(\n",
        "    tools=[weather_time_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# STEP 7: Take user input and invoke agent\n",
        "city = input(\"🌍 Enter a city name: \").strip()\n",
        "response = agent.run(f\"What's the weather and IST time in {city}?\")\n",
        "print(\"\\n💬 Agent response:\\n\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1ErbmzxGjB5",
        "outputId": "ac28297d-ec31-4c62-c418-09639e4a1615"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 Enter a city name: London\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `weather_time_tool` with `London`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m📍 London, United Kingdom\n",
            "🌡️ Temperature: 20.0°C\n",
            "💨 Wind Speed: 8.2 km/h\n",
            "🕒 Current IST Time: 04:50 PM\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in London is 20°C with a wind speed of 8.2 km/h. The IST time in London is 04:50 PM.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "💬 Agent response:\n",
            " The current weather in London is 20°C with a wind speed of 8.2 km/h. The IST time in London is 04:50 PM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# More Dynamic Example"
      ],
      "metadata": {
        "id": "GSTF0PgrGqlj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install dependencies\n",
        "!pip install -q langchain langchain-openai requests pytz\n",
        "\n",
        "# STEP 2: Imports and API Key\n",
        "import os\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from google.colab import userdata\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# STEP 3: Set your OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# STEP 4: Define the tool\n",
        "def get_weather_and_times(city: str) -> str:\n",
        "    try:\n",
        "        # Geocode to get latitude, longitude, timezone\n",
        "        geo_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\"\n",
        "        geo_response = requests.get(geo_url).json()\n",
        "        if \"results\" not in geo_response:\n",
        "            return f\"❌ City '{city}' not found.\"\n",
        "\n",
        "        info = geo_response[\"results\"][0]\n",
        "        name = info[\"name\"]\n",
        "        country = info.get(\"country\", \"\")\n",
        "        lat = info[\"latitude\"]\n",
        "        lon = info[\"longitude\"]\n",
        "        timezone = info.get(\"timezone\", \"UTC\")\n",
        "\n",
        "        # Get weather data\n",
        "        weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
        "        weather_data = requests.get(weather_url).json()\n",
        "        current = weather_data[\"current_weather\"]\n",
        "        temp = current[\"temperature\"]\n",
        "        wind = current[\"windspeed\"]\n",
        "\n",
        "        # Local time at city\n",
        "        city_time = datetime.now(pytz.timezone(timezone)).strftime(\"%I:%M %p\")\n",
        "\n",
        "        # Current IST time\n",
        "        ist_time = datetime.now(pytz.timezone(\"Asia/Kolkata\")).strftime(\"%I:%M %p\")\n",
        "\n",
        "        return (f\"📍 {name}, {country}\\n\"\n",
        "                f\"🕑 Local Time: {city_time} ({timezone})\\n\"\n",
        "                f\"🕒 IST Time: {ist_time}\\n\"\n",
        "                f\"🌡️ Temperature: {temp}°C\\n\"\n",
        "                f\"💨 Wind: {wind} km/h\")\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ Error: {str(e)}\"\n",
        "\n",
        "# STEP 5: Wrap tool\n",
        "weather_tool = Tool(\n",
        "    name=\"weather_time_tool\",\n",
        "    func=get_weather_and_times,\n",
        "    description=\"Get weather, local time, and IST time. Input should be a city name.\"\n",
        ")\n",
        "\n",
        "# STEP 6: Create Agent\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
        "agent = initialize_agent(\n",
        "    tools=[weather_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# STEP 7: Run in loop\n",
        "print(\"🌍 Ask for any city's weather & time. Type 'exit' to quit.\\n\")\n",
        "while True:\n",
        "    city = input(\"Enter city name: \").strip()\n",
        "    if city.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"👋 Exiting. Stay informed!\")\n",
        "        break\n",
        "    response = agent.run(f\"Get weather and time in {city}\")\n",
        "    print(\"\\n💬 Agent response:\\n\", response, \"\\n\" + \"-\"*60 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtIKA30iH3un",
        "outputId": "00db7cc6-0f76-4702-ec6a-3ec6c539ffbe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 Ask for any city's weather & time. Type 'exit' to quit.\n",
            "\n",
            "Enter city name: London\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `weather_time_tool` with `London`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m📍 London, United Kingdom\n",
            "🕑 Local Time: 12:28 PM (Europe/London)\n",
            "🕒 IST Time: 04:58 PM\n",
            "🌡️ Temperature: 20.0°C\n",
            "💨 Wind: 8.2 km/h\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in London is 20.0°C with a wind speed of 8.2 km/h. The local time in London is 12:28 PM, and the IST time is 04:58 PM.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "💬 Agent response:\n",
            " The current weather in London is 20.0°C with a wind speed of 8.2 km/h. The local time in London is 12:28 PM, and the IST time is 04:58 PM. \n",
            "------------------------------------------------------------\n",
            "\n",
            "Enter city name: New York\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `weather_time_tool` with `New York`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m📍 New York, United States\n",
            "🕑 Local Time: 07:28 AM (America/New_York)\n",
            "🕒 IST Time: 04:58 PM\n",
            "🌡️ Temperature: 21.6°C\n",
            "💨 Wind: 9.9 km/h\u001b[0m\u001b[32;1m\u001b[1;3mThe current local time in New York is 07:28 AM, and the temperature is 21.6°C with a wind speed of 9.9 km/h.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "💬 Agent response:\n",
            " The current local time in New York is 07:28 AM, and the temperature is 21.6°C with a wind speed of 9.9 km/h. \n",
            "------------------------------------------------------------\n",
            "\n",
            "Enter city name: colambo\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `weather_time_tool` with `Colombo`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m📍 Colombo, Sri Lanka\n",
            "🕑 Local Time: 04:59 PM (Asia/Colombo)\n",
            "🕒 IST Time: 04:59 PM\n",
            "🌡️ Temperature: 26.8°C\n",
            "💨 Wind: 18.6 km/h\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in Colombo is 26.8°C with a wind speed of 18.6 km/h. The local time in Colombo is 04:59 PM.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "💬 Agent response:\n",
            " The current weather in Colombo is 26.8°C with a wind speed of 18.6 km/h. The local time in Colombo is 04:59 PM. \n",
            "------------------------------------------------------------\n",
            "\n",
            "Enter city name: pune\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `weather_time_tool` with `Pune`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m📍 Pune, India\n",
            "🕑 Local Time: 04:59 PM (Asia/Kolkata)\n",
            "🕒 IST Time: 04:59 PM\n",
            "🌡️ Temperature: 27.0°C\n",
            "💨 Wind: 10.2 km/h\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in Pune is 27°C with a wind speed of 10.2 km/h. The local time in Pune is 4:59 PM.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "💬 Agent response:\n",
            " The current weather in Pune is 27°C with a wind speed of 10.2 km/h. The local time in Pune is 4:59 PM. \n",
            "------------------------------------------------------------\n",
            "\n",
            "Enter city name: exit\n",
            "👋 Exiting. Stay informed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End of the Notebook"
      ],
      "metadata": {
        "id": "Rmg5iYkrH4TI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n3uYalKtJN4y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}