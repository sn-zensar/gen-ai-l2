{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Document Loaders"
      ],
      "metadata": {
        "id": "kSESOh5V2ZwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SiyQ_9E0Kjd"
      },
      "outputs": [],
      "source": [
        "# Example 1 - Text Doc loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community pypdf beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz-OiB8X20cR",
        "outputId": "422222bc-5d51-4fcb-da36-0f86aa031ae5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, pypdf, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 pypdf-5.9.0 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8_utiwy68BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"/content/sample.txt\")  # Make sure the file is uploaded\n",
        "docs = loader.load()\n",
        "\n",
        "print(docs[0].page_content)  # Show first document's content\n"
      ],
      "metadata": {
        "id": "3Fj_nbyk2ZYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260569ee-c94f-418e-a5c9-4ed9a0bf6bb7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿ \n",
            "Detailed Learning Guide: AI, ML, Deep Learning, GenAI, Prompt Engineering, Copilot, LangChain, Agentic AI, and RAG\n",
            "1. Quick Overview: AI, ML, Deep Learning, and Generative AI\n",
            "1.1 Artificial Intelligence (AI)\n",
            "·       Definition: AI is the overarching concept of machines that can perform tasks that typically require human intelligence, such as reasoning, decision-making, and perception.\n",
            "·       Types: Rule-based systems, expert systems, search algorithms, and adaptive software.\n",
            "·       Key Attributes: Problem-solving, logical deduction, language understanding, and planning.\n",
            "1.2 Machine Learning (ML)\n",
            "·       Definition: A subset of AI where algorithms learn from data to make predictions or decisions without explicit programming.\n",
            "·       Categories:\n",
            "o   Supervised Learning: Learning from labeled data (e.g., spam detection).\n",
            "o   Unsupervised Learning: Finding patterns in unlabeled data (e.g., clustering).\n",
            "o   Reinforcement Learning: Agents learn by interacting with the environment and receiving rewards/punishments.\n",
            "·       Common Algorithms: Linear regression, decision trees, k-means clustering, support vector machines.\n",
            "1.3 Deep Learning (DL)\n",
            "·       Definition: A specialized branch of ML using artificial neural networks with many layers to process data and learn complex patterns.\n",
            "·       Features: Capable of handling unstructured data like images, speech, and text.\n",
            "·       Popular Architectures: Convolutional Neural Networks (CNNs) for image data, Recurrent Neural Networks (RNNs) for sequence data, and Transformers for NLP tasks[1][2][3].\n",
            "1.4 Generative AI (GenAI)\n",
            "·       Definition: Uses models (often deep neural networks) to create new content—text, images, code, etc.—that closely mimics human-generated data.\n",
            "·       Key Models: Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Large Language Models (LLMs).\n",
            "·       Applications: Text generation, art, deepfakes, music composition, data augmentation[1][2][3].\n",
            "Hands-On Example:\n",
            "·       Task: Train a simple neural network to classify images (use frameworks like TensorFlow or PyTorch).\n",
            "·       Activity: Use a public dataset (e.g., MNIST digits) and build, train, and evaluate a CNN model that recognizes handwritten digits.\n",
            "2. Prompt Engineering: Theory & Hands-On\n",
            "2.1 What Is a Prompt?\n",
            "·       Definition: A prompt is a structured input given to a generative model to elicit a specific response.\n",
            "·       Importance: The quality of the output largely depends on the clarity and structure of the prompt itself[4][5].\n",
            "2.2 Prompt Engineering Techniques\n",
            "·       Zero-Shot Prompting: No examples provided, just ask the model to perform a task.\n",
            "·       One-Shot/Few-Shot Prompting: Back up instructions with 1 or a few examples for better accuracy.\n",
            "·       Chain-of-Thought Prompting: Request the model to explain its reasoning or steps.\n",
            "·       Tree-of-Thought Prompting: Model evaluates multiple action paths, discards poor ones, deepens logical depth.\n",
            "·       Iterative Prompting: Refine prompts based on prior responses, adding precision in each iteration.\n",
            "·       Negative Prompting: Specify what NOT to do or include in the output.\n",
            "·       Generated Knowledge Prompting: Combine known ideas to prompt new, creative outputs[4][5].\n",
            "2.3 Best Practices\n",
            "·       Specify output format (list, table, JSON).\n",
            "·       Provide examples for complex requests.\n",
            "·       Repeat/reframe to debug if the result is off.\n",
            "·       Add constraints for tone, length, or detail needed.\n",
            "Hands-On Exercises\n",
            "1.      Zero-Shot Example:\n",
            "o   Prompt: \"Summarize this article in two sentences.\"\n",
            "2.     Few-Shot Example:\n",
            "o   Provide two input-output pairs before requesting the model to follow suit on a third sample.\n",
            "3.     Chain-of-Thought Example:\n",
            "o   Prompt: \"Explain why the sky is blue. Give the answer step by step.\"\n",
            "4.     Role Assignment Example:\n",
            "o   Prompt: \"You are a travel guide. Recommend three places to visit in Paris and explain why.\"\n",
            "3. Copilot (Assistive AI): Theory & Hands-On\n",
            "3.1 What Is Copilot?\n",
            "·       Definition: Copilot refers to integrated AI assistants in software environments that augment user productivity by providing suggestions, automating tasks, and learning from context.\n",
            "·       How It Works: Built using natural language processing and ML, Copilots interpret user commands, contextually generate content, and automate workflows across tools like code editors, office suites, and customer support systems[6][7][8].\n",
            "3.2 Key Features\n",
            "·       Context-Aware Assistance: Understands current user activity and offers relevant support.\n",
            "·       Task Automation: Automates repetitive or mundane workflows.\n",
            "·       Personalization: Learns individual work styles and adapts recommendations.\n",
            "·       Error Detection: Spots and corrects code or grammar errors.\n",
            "·       Integration: Embedded within popular platforms—Microsoft 365, GitHub, etc.\n",
            "3.3 Use Cases\n",
            "·       Auto-complete code while programming.\n",
            "·       Generate document summaries or draft emails in office apps.\n",
            "·       Plan and schedule meetings from within chat platforms.\n",
            "Hands-On Exercise\n",
            "·       Task: Use GitHub Copilot in Visual Studio Code to implement a Python function based on comments. Assess and modify the suggestions for correctness.\n",
            "·       Activity: Use Microsoft 365 Copilot to summarize meeting notes, draft emails, or automate data analytics.\n",
            "4. LangChain: Theory & Hands-On\n",
            "4.1 What Is LangChain?\n",
            "·       Definition: Open-source orchestration toolkit for connecting LLMs to external data, APIs, and multi-step workflows.\n",
            "·       Key Components:\n",
            "o   Chains: Sequences (single or multi-step) combining LLMs and external tools.\n",
            "o   Prompt Management: Tools for designing, templating, and reusing prompts.\n",
            "o   Retrievers: Fetch data from knowledge bases or databases for the LLM.\n",
            "o   Agents: Enable decision-making and dynamic tool use by the application[9][10][11].\n",
            "4.2 Typical Use Cases\n",
            "·       Retrieval-Augmented QA: Use external documents for context-grounded question answering.\n",
            "·       Chatbots: Context-rich, stateful conversational agents.\n",
            "·       Autonomous Agents: Automate business workflows based on complex triggers.\n",
            "Hands-On Example\n",
            "·       Task: Build a simple Q&A bot using LangChain, connecting OpenAI’s GPT-4 to a custom document set for RAG-based answers.\n",
            "·       Steps:\n",
            "o   Load documents\n",
            "o   Set up retriever and embedding\n",
            "o   Chain the retriever with a prompt template\n",
            "o   Query the chain and evaluate the responses on custom queries\n",
            "5. Agentic AI: Theory & Hands-On\n",
            "5.1 What Is Agentic AI?\n",
            "·       Definition: AI systems composed of autonomous agents that can perceive, decide, act, and learn to achieve complex goals with minimal supervision.\n",
            "·       Key Elements:\n",
            "o   Perception: Collect data from environments or users.\n",
            "o   Reasoning & Planning: Formulate strategies/actions using LLMs and other AI models.\n",
            "o   Action Execution: Trigger tasks or call external software via APIs or tools.\n",
            "o   Learning Loop: Continually adapt actions based on outcomes and new data.\n",
            "·       Distinctive Features: Autonomy, intent-driven operation, real-time adaptation, and agency, going beyond deterministic automation to flexible, goal-driven behavior[12][13].\n",
            "5.2 Use Cases\n",
            "·       Automated cybersecurity monitoring and remediation.\n",
            "·       Logistics optimization agents.\n",
            "·       HR bots that coordinate onboarding across multiple systems.\n",
            "Hands-On Project\n",
            "·       Task: Create an agent with LangChain (or any agentic AI library) that, given a user query, can decide whether to search the web, query a database, or draft an email, and then execute actions accordingly.\n",
            "·       Steps: Define agent’s decision rules; implement action handlers and human-in-the-loop checkpoints.\n",
            "6. Retrieval-Augmented Generation (RAG): Theory & Hands-On\n",
            "6.1 What Is RAG?\n",
            "·       Definition: A modern LLM enhancement technique in which the model retrieves relevant information from specified datasets or knowledge bases before generating a response, ensuring outputs are grounded, accurate, and up-to-date[14][15].\n",
            "·       Components:\n",
            "o   Embedding Model: Converts documents to vector representations.\n",
            "o   Retriever: Searches for relevant documents using embeddings.\n",
            "o   Reranker (optional): Scores and ranks relevant documents.\n",
            "o   Language Model: Generates human-like output grounded in retrieved content.\n",
            "6.2 Benefits\n",
            "·       Reduces hallucination and misinformation.\n",
            "·       Enables up-to-date responses without retraining LLMs.\n",
            "·       Allows domain adaptation by grounding answers in proprietary or recent data.\n",
            "6.3 Typical Applications\n",
            "·       Corporate chatbots that cite internal policy documents.\n",
            "·       Q&A bots that include URLs or text references.\n",
            "·       Personalized assistants fetching data from up-to-date knowledge bases.\n",
            "Hands-On Exercise\n",
            "·       Task: Build a RAG pipeline using LangChain + OpenAI:\n",
            "o   Ingest a set of company FAQs.\n",
            "o   Convert to embeddings, store in a vector DB (e.g., FAISS).\n",
            "o   Implement a simple app that takes user queries, retrieves relevant content, and lets GPT-4 compose informed, referenced answers.\n",
            "7. Summary Table: Technologies and Typical Hands-On Projects\n",
            "Topic\tTheory Focus\tHands-On Focus Example\n",
            "AI/ML/DL/GenAI\tConcepts, architectures, differences\tBuild a neural network for image classification\n",
            "Prompt Engg.\tPrompt types, techniques, design principles\tExperiment with zero-shot, few-shot, and CoT prompting\n",
            "Copilot\tAssistive AI features, contextual learning\tUse GitHub Copilot or MS 365 Copilot for real-world tasks\n",
            "LangChain\tBuilding LLM-powered workflows and apps\tQ&A bot with LangChain and vector DB\n",
            "Agentic AI\tAutonomous, multi-step, decision agents\tAgent managing emails, web search, and data tasks\n",
            "RAG\tRetrieval with generation for grounded answers\tImplement RAG Q&A using LangChain or huggingface pipelines\n",
            " \n",
            "⁂\n",
            "\n",
            "1.      https://synoptek.com/insights/it-blogs/data-insights/ai-ml-dl-and-generative-ai-face-off-a-comparative-analysis/  \n",
            "2.     https://www.sumologic.com/blog/machine-learning-deep-learning  \n",
            "3.     https://k21academy.com/ai-ml/deep-learning-ml-generative-ai/  \n",
            "4.     https://viso.ai/deep-learning/prompt-engineering/  \n",
            "5.     https://dev.to/jeremycmorgan/the-essential-guide-to-prompt-engineering-for-creators-and-innovators-28pk  \n",
            "6.     https://xpand-it.com/en/artificial-intelligence/what-is-copilot-understanding-ai-powered-assistant/ \n",
            "7.     https://www.xpand-it.com/blog/what-is-copilot-understanding-ai-powered-assistant/ \n",
            "8.     https://learn.microsoft.com/en-us/microsoft-cloud/dev/copilot/overview \n",
            "9.     https://cloud.google.com/use-cases/langchain \n",
            "10.  https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained \n",
            "11.   https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/ \n",
            "12.   https://www.tanium.com/blog/what-is-agentic-ai/ \n",
            "13.   https://www.ibm.com/think/topics/agentic-ai \n",
            "14.   https://en.wikipedia.org/wiki/Retrieval-augmented_generation \n",
            "15.   https://www.superannotate.com/blog/rag-explained \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - Text loader , data & metadata retriever"
      ],
      "metadata": {
        "id": "6IauOjxu2sbk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"/content/sample.txt\")  # Upload your .txt file to /content\n",
        "docs = loader.load()\n",
        "\n",
        "print(\"📄 Page Content:\\n\", docs[0].page_content)\n",
        "print(\"🗂️ Metadata:\\n\", docs[0].metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUlR0G3d7DSR",
        "outputId": "eb3a9044-db5f-485c-a343-b4b95f39bc86"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Page Content:\n",
            " ﻿ \n",
            "Detailed Learning Guide: AI, ML, Deep Learning, GenAI, Prompt Engineering, Copilot, LangChain, Agentic AI, and RAG\n",
            "1. Quick Overview: AI, ML, Deep Learning, and Generative AI\n",
            "1.1 Artificial Intelligence (AI)\n",
            "·       Definition: AI is the overarching concept of machines that can perform tasks that typically require human intelligence, such as reasoning, decision-making, and perception.\n",
            "·       Types: Rule-based systems, expert systems, search algorithms, and adaptive software.\n",
            "·       Key Attributes: Problem-solving, logical deduction, language understanding, and planning.\n",
            "1.2 Machine Learning (ML)\n",
            "·       Definition: A subset of AI where algorithms learn from data to make predictions or decisions without explicit programming.\n",
            "·       Categories:\n",
            "o   Supervised Learning: Learning from labeled data (e.g., spam detection).\n",
            "o   Unsupervised Learning: Finding patterns in unlabeled data (e.g., clustering).\n",
            "o   Reinforcement Learning: Agents learn by interacting with the environment and receiving rewards/punishments.\n",
            "·       Common Algorithms: Linear regression, decision trees, k-means clustering, support vector machines.\n",
            "1.3 Deep Learning (DL)\n",
            "·       Definition: A specialized branch of ML using artificial neural networks with many layers to process data and learn complex patterns.\n",
            "·       Features: Capable of handling unstructured data like images, speech, and text.\n",
            "·       Popular Architectures: Convolutional Neural Networks (CNNs) for image data, Recurrent Neural Networks (RNNs) for sequence data, and Transformers for NLP tasks[1][2][3].\n",
            "1.4 Generative AI (GenAI)\n",
            "·       Definition: Uses models (often deep neural networks) to create new content—text, images, code, etc.—that closely mimics human-generated data.\n",
            "·       Key Models: Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Large Language Models (LLMs).\n",
            "·       Applications: Text generation, art, deepfakes, music composition, data augmentation[1][2][3].\n",
            "Hands-On Example:\n",
            "·       Task: Train a simple neural network to classify images (use frameworks like TensorFlow or PyTorch).\n",
            "·       Activity: Use a public dataset (e.g., MNIST digits) and build, train, and evaluate a CNN model that recognizes handwritten digits.\n",
            "2. Prompt Engineering: Theory & Hands-On\n",
            "2.1 What Is a Prompt?\n",
            "·       Definition: A prompt is a structured input given to a generative model to elicit a specific response.\n",
            "·       Importance: The quality of the output largely depends on the clarity and structure of the prompt itself[4][5].\n",
            "2.2 Prompt Engineering Techniques\n",
            "·       Zero-Shot Prompting: No examples provided, just ask the model to perform a task.\n",
            "·       One-Shot/Few-Shot Prompting: Back up instructions with 1 or a few examples for better accuracy.\n",
            "·       Chain-of-Thought Prompting: Request the model to explain its reasoning or steps.\n",
            "·       Tree-of-Thought Prompting: Model evaluates multiple action paths, discards poor ones, deepens logical depth.\n",
            "·       Iterative Prompting: Refine prompts based on prior responses, adding precision in each iteration.\n",
            "·       Negative Prompting: Specify what NOT to do or include in the output.\n",
            "·       Generated Knowledge Prompting: Combine known ideas to prompt new, creative outputs[4][5].\n",
            "2.3 Best Practices\n",
            "·       Specify output format (list, table, JSON).\n",
            "·       Provide examples for complex requests.\n",
            "·       Repeat/reframe to debug if the result is off.\n",
            "·       Add constraints for tone, length, or detail needed.\n",
            "Hands-On Exercises\n",
            "1.      Zero-Shot Example:\n",
            "o   Prompt: \"Summarize this article in two sentences.\"\n",
            "2.     Few-Shot Example:\n",
            "o   Provide two input-output pairs before requesting the model to follow suit on a third sample.\n",
            "3.     Chain-of-Thought Example:\n",
            "o   Prompt: \"Explain why the sky is blue. Give the answer step by step.\"\n",
            "4.     Role Assignment Example:\n",
            "o   Prompt: \"You are a travel guide. Recommend three places to visit in Paris and explain why.\"\n",
            "3. Copilot (Assistive AI): Theory & Hands-On\n",
            "3.1 What Is Copilot?\n",
            "·       Definition: Copilot refers to integrated AI assistants in software environments that augment user productivity by providing suggestions, automating tasks, and learning from context.\n",
            "·       How It Works: Built using natural language processing and ML, Copilots interpret user commands, contextually generate content, and automate workflows across tools like code editors, office suites, and customer support systems[6][7][8].\n",
            "3.2 Key Features\n",
            "·       Context-Aware Assistance: Understands current user activity and offers relevant support.\n",
            "·       Task Automation: Automates repetitive or mundane workflows.\n",
            "·       Personalization: Learns individual work styles and adapts recommendations.\n",
            "·       Error Detection: Spots and corrects code or grammar errors.\n",
            "·       Integration: Embedded within popular platforms—Microsoft 365, GitHub, etc.\n",
            "3.3 Use Cases\n",
            "·       Auto-complete code while programming.\n",
            "·       Generate document summaries or draft emails in office apps.\n",
            "·       Plan and schedule meetings from within chat platforms.\n",
            "Hands-On Exercise\n",
            "·       Task: Use GitHub Copilot in Visual Studio Code to implement a Python function based on comments. Assess and modify the suggestions for correctness.\n",
            "·       Activity: Use Microsoft 365 Copilot to summarize meeting notes, draft emails, or automate data analytics.\n",
            "4. LangChain: Theory & Hands-On\n",
            "4.1 What Is LangChain?\n",
            "·       Definition: Open-source orchestration toolkit for connecting LLMs to external data, APIs, and multi-step workflows.\n",
            "·       Key Components:\n",
            "o   Chains: Sequences (single or multi-step) combining LLMs and external tools.\n",
            "o   Prompt Management: Tools for designing, templating, and reusing prompts.\n",
            "o   Retrievers: Fetch data from knowledge bases or databases for the LLM.\n",
            "o   Agents: Enable decision-making and dynamic tool use by the application[9][10][11].\n",
            "4.2 Typical Use Cases\n",
            "·       Retrieval-Augmented QA: Use external documents for context-grounded question answering.\n",
            "·       Chatbots: Context-rich, stateful conversational agents.\n",
            "·       Autonomous Agents: Automate business workflows based on complex triggers.\n",
            "Hands-On Example\n",
            "·       Task: Build a simple Q&A bot using LangChain, connecting OpenAI’s GPT-4 to a custom document set for RAG-based answers.\n",
            "·       Steps:\n",
            "o   Load documents\n",
            "o   Set up retriever and embedding\n",
            "o   Chain the retriever with a prompt template\n",
            "o   Query the chain and evaluate the responses on custom queries\n",
            "5. Agentic AI: Theory & Hands-On\n",
            "5.1 What Is Agentic AI?\n",
            "·       Definition: AI systems composed of autonomous agents that can perceive, decide, act, and learn to achieve complex goals with minimal supervision.\n",
            "·       Key Elements:\n",
            "o   Perception: Collect data from environments or users.\n",
            "o   Reasoning & Planning: Formulate strategies/actions using LLMs and other AI models.\n",
            "o   Action Execution: Trigger tasks or call external software via APIs or tools.\n",
            "o   Learning Loop: Continually adapt actions based on outcomes and new data.\n",
            "·       Distinctive Features: Autonomy, intent-driven operation, real-time adaptation, and agency, going beyond deterministic automation to flexible, goal-driven behavior[12][13].\n",
            "5.2 Use Cases\n",
            "·       Automated cybersecurity monitoring and remediation.\n",
            "·       Logistics optimization agents.\n",
            "·       HR bots that coordinate onboarding across multiple systems.\n",
            "Hands-On Project\n",
            "·       Task: Create an agent with LangChain (or any agentic AI library) that, given a user query, can decide whether to search the web, query a database, or draft an email, and then execute actions accordingly.\n",
            "·       Steps: Define agent’s decision rules; implement action handlers and human-in-the-loop checkpoints.\n",
            "6. Retrieval-Augmented Generation (RAG): Theory & Hands-On\n",
            "6.1 What Is RAG?\n",
            "·       Definition: A modern LLM enhancement technique in which the model retrieves relevant information from specified datasets or knowledge bases before generating a response, ensuring outputs are grounded, accurate, and up-to-date[14][15].\n",
            "·       Components:\n",
            "o   Embedding Model: Converts documents to vector representations.\n",
            "o   Retriever: Searches for relevant documents using embeddings.\n",
            "o   Reranker (optional): Scores and ranks relevant documents.\n",
            "o   Language Model: Generates human-like output grounded in retrieved content.\n",
            "6.2 Benefits\n",
            "·       Reduces hallucination and misinformation.\n",
            "·       Enables up-to-date responses without retraining LLMs.\n",
            "·       Allows domain adaptation by grounding answers in proprietary or recent data.\n",
            "6.3 Typical Applications\n",
            "·       Corporate chatbots that cite internal policy documents.\n",
            "·       Q&A bots that include URLs or text references.\n",
            "·       Personalized assistants fetching data from up-to-date knowledge bases.\n",
            "Hands-On Exercise\n",
            "·       Task: Build a RAG pipeline using LangChain + OpenAI:\n",
            "o   Ingest a set of company FAQs.\n",
            "o   Convert to embeddings, store in a vector DB (e.g., FAISS).\n",
            "o   Implement a simple app that takes user queries, retrieves relevant content, and lets GPT-4 compose informed, referenced answers.\n",
            "7. Summary Table: Technologies and Typical Hands-On Projects\n",
            "Topic\tTheory Focus\tHands-On Focus Example\n",
            "AI/ML/DL/GenAI\tConcepts, architectures, differences\tBuild a neural network for image classification\n",
            "Prompt Engg.\tPrompt types, techniques, design principles\tExperiment with zero-shot, few-shot, and CoT prompting\n",
            "Copilot\tAssistive AI features, contextual learning\tUse GitHub Copilot or MS 365 Copilot for real-world tasks\n",
            "LangChain\tBuilding LLM-powered workflows and apps\tQ&A bot with LangChain and vector DB\n",
            "Agentic AI\tAutonomous, multi-step, decision agents\tAgent managing emails, web search, and data tasks\n",
            "RAG\tRetrieval with generation for grounded answers\tImplement RAG Q&A using LangChain or huggingface pipelines\n",
            " \n",
            "⁂\n",
            "\n",
            "1.      https://synoptek.com/insights/it-blogs/data-insights/ai-ml-dl-and-generative-ai-face-off-a-comparative-analysis/  \n",
            "2.     https://www.sumologic.com/blog/machine-learning-deep-learning  \n",
            "3.     https://k21academy.com/ai-ml/deep-learning-ml-generative-ai/  \n",
            "4.     https://viso.ai/deep-learning/prompt-engineering/  \n",
            "5.     https://dev.to/jeremycmorgan/the-essential-guide-to-prompt-engineering-for-creators-and-innovators-28pk  \n",
            "6.     https://xpand-it.com/en/artificial-intelligence/what-is-copilot-understanding-ai-powered-assistant/ \n",
            "7.     https://www.xpand-it.com/blog/what-is-copilot-understanding-ai-powered-assistant/ \n",
            "8.     https://learn.microsoft.com/en-us/microsoft-cloud/dev/copilot/overview \n",
            "9.     https://cloud.google.com/use-cases/langchain \n",
            "10.  https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained \n",
            "11.   https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/ \n",
            "12.   https://www.tanium.com/blog/what-is-agentic-ai/ \n",
            "13.   https://www.ibm.com/think/topics/agentic-ai \n",
            "14.   https://en.wikipedia.org/wiki/Retrieval-augmented_generation \n",
            "15.   https://www.superannotate.com/blog/rag-explained \n",
            "\n",
            "🗂️ Metadata:\n",
            " {'source': '/content/sample.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# csv loader"
      ],
      "metadata": {
        "id": "SpM05rBr7Duw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import CSVLoader\n",
        "\n",
        "loader = CSVLoader(file_path=\"/content/data.csv\")  # Upload your .csv\n",
        "docs = loader.load()\n",
        "\n",
        "print(\"📄 First Row Content:\\n\", docs[0].page_content)\n",
        "print(\"🗂️ Metadata:\\n\", docs[0].metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edtbLiRi7TDQ",
        "outputId": "f7db440c-42ad-43bc-d1c7-cb3497816df1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 First Row Content:\n",
            " SO43701: SO43704\n",
            "1: 1\n",
            "2019-07-01: 2019-07-01\n",
            "Christy Zhu: Julio Ruiz\n",
            "christy12@adventure-works.com: julio1@adventure-works.com\n",
            "Mountain-100 Silver, 44: Mountain-100 Black, 48\n",
            "3399.99: 3374.99\n",
            "271.9992: 269.9992\n",
            "🗂️ Metadata:\n",
            " {'source': '/content/data.csv', 'row': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pdf loader"
      ],
      "metadata": {
        "id": "FHan3s437T6H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/example.pdf\")  # Upload your .pdf\n",
        "pages = loader.load()\n",
        "\n",
        "print(\"📄 Page 1 Content:\\n\", pages[0].page_content[:500])\n",
        "print(\"🗂️ Metadata:\\n\", pages[0].metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTRF6Q5J7aIQ",
        "outputId": "83bfc160-9119-43de-916d-575592731a29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Page 1 Content:\n",
            " \n",
            "🗂️ Metadata:\n",
            " {'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.3 (Windows)', 'creationdate': '2024-04-15T20:37:40+01:00', 'moddate': '2024-04-15T20:37:52+01:00', 'trapped': '/False', 'source': '/content/example.pdf', 'total_pages': 118, 'page': 0, 'page_label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# web page loader"
      ],
      "metadata": {
        "id": "OKRlryhW7boY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.databricks.com/aws/en/machine-learning/\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(\"📄 Web Page Content:\\n\", docs[0].page_content[:500])\n",
        "print(\"🗂️ Metadata:\\n\", docs[0].metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbXUkhzb7cy3",
        "outputId": "4a0ca056-2413-4980-f91f-8d93205213f3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Web Page Content:\n",
            " AI and machine learning on Databricks | Databricks Documentation\n",
            "Skip to main contentGet startedDevelopersReferenceRelease notesResourcesSupportKnowledge BaseCommunityTrainingFeedbackEnglishEnglish日本語PortuguêsAWSAzureGCPSAPTry DatabricksAI and machine learningOn this pageAI and machine learning on Databricks\n",
            "Build, deploy, and manage AI and machine learning applications with Mosaic AI, an integrated platform that unifies the entire AI lifecycle from data preparation to production monitoring.\n",
            "For\n",
            "🗂️ Metadata:\n",
            " {'source': 'https://docs.databricks.com/aws/en/machine-learning/', 'title': 'AI and machine learning on Databricks | Databricks Documentation', 'description': 'Build AI and machine learning applications on Databricks using unified data and ML platform capabilities.', 'language': 'en'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets implement the doc loaders using LLM to extract from knowledge base"
      ],
      "metadata": {
        "id": "yew7nL8R8VL7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1 - Text Loader"
      ],
      "metadata": {
        "id": "nwHbL3NT9b0j"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-openai langchain-community pypdf beautifulsoup4 striprtf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmuP4IPz9f3q",
        "outputId": "a3a99b21-9f16-4910-9f51-5a5f8104bdba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Collecting striprtf\n",
            "  Downloading striprtf-0.0.29-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.97.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.29-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: striprtf, langchain-openai\n",
            "Successfully installed langchain-openai-0.3.28 striprtf-0.0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "DVuHAmdJ9VVq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load doc"
      ],
      "metadata": {
        "id": "QXysWkiG9rEU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# Load file\n",
        "loader = TextLoader(\"/content/sample.txt\")\n",
        "docs = loader.load()\n",
        "document_text = docs[0].page_content\n",
        "\n",
        "# Setup GPT model\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# Setup prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that summarizes documents.\"),\n",
        "    (\"human\", \"Summarize the following content:\\n\\n{input_text}\")\n",
        "])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uLV1jAVg9WCK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate summary"
      ],
      "metadata": {
        "id": "SAjbryho9d0a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm\n",
        "\n",
        "response = chain.invoke({\"input_text\": document_text})\n",
        "\n",
        "print(\"📄 Summary:\\n\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAHLroWn9tcD",
        "outputId": "769c2ed9-9ec6-4c86-802d-2b03f35a789c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Summary:\n",
            " The document is a detailed learning guide covering various AI-related topics, including AI, ML, Deep Learning, Generative AI, Prompt Engineering, Copilot, LangChain, Agentic AI, and Retrieval-Augmented Generation (RAG). Here's a summary of each section:\n",
            "\n",
            "1. **AI, ML, Deep Learning, and Generative AI**:\n",
            "   - **AI**: Machines performing tasks requiring human intelligence, including reasoning and decision-making.\n",
            "   - **ML**: AI subset where algorithms learn from data to make predictions or decisions. Includes supervised, unsupervised, and reinforcement learning.\n",
            "   - **Deep Learning**: A branch of ML using neural networks with many layers to process complex data.\n",
            "   - **Generative AI**: Models that create new content mimicking human-generated data, using techniques like GANs and VAEs.\n",
            "\n",
            "2. **Prompt Engineering**:\n",
            "   - Involves crafting structured inputs (prompts) for generative models to elicit specific responses.\n",
            "   - Techniques include zero-shot, few-shot, chain-of-thought, and iterative prompting.\n",
            "   - Best practices include specifying output formats and providing examples for complex requests.\n",
            "\n",
            "3. **Copilot (Assistive AI)**:\n",
            "   - AI assistants integrated into software to enhance productivity by providing suggestions and automating tasks.\n",
            "   - Features include context-aware assistance, task automation, personalization, and error detection.\n",
            "\n",
            "4. **LangChain**:\n",
            "   - An open-source toolkit for connecting large language models (LLMs) to external data and workflows.\n",
            "   - Key components include chains, prompt management, retrievers, and agents.\n",
            "   - Used for tasks like retrieval-augmented QA and building chatbots.\n",
            "\n",
            "5. **Agentic AI**:\n",
            "   - AI systems with autonomous agents that perceive, decide, act, and learn to achieve goals with minimal supervision.\n",
            "   - Features include autonomy, intent-driven operation, and real-time adaptation.\n",
            "\n",
            "6. **Retrieval-Augmented Generation (RAG)**:\n",
            "   - Enhances LLMs by retrieving relevant information from datasets before generating responses.\n",
            "   - Benefits include reducing misinformation and enabling up-to-date responses.\n",
            "\n",
            "The guide also includes hands-on exercises and projects for each topic, such as building neural networks, experimenting with prompt engineering techniques, using Copilot for coding tasks, creating Q&A bots with LangChain, and implementing RAG pipelines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - PDF Loader"
      ],
      "metadata": {
        "id": "ZmubdTO-9t3A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load doc\n"
      ],
      "metadata": {
        "id": "aJ0cmF6T94Z-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load file\n",
        "loader = PyPDFLoader(\"/content/example.pdf\")\n",
        "docs = loader.load()\n",
        "document_text = docs[10].page_content\n",
        "\n",
        "# Setup GPT model\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# Setup prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that summarizes documents.\"),\n",
        "    (\"human\", \"Summarize the following content:\\n\\n{input_text}\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "L7tnmDq891co"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate summary"
      ],
      "metadata": {
        "id": "9Smljvdz-Dr1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm\n",
        "\n",
        "response = chain.invoke({\"input_text\": document_text})\n",
        "\n",
        "print(\"📄 Summary:\\n\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qndzHAzy-E3v",
        "outputId": "38c873cc-1bf3-4d73-919f-67c0bfa01ed6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Summary:\n",
            " The document provides a comparison of various AI models, including DBRX, Instruct GPT-3.57, GPT-48, Claude 3, Gemini 1.0 Pro, Gemini 1.5 Pro, Mistral Medium, and Mistral Large, across different benchmarks. The benchmarks include MT Bench, MMLU 5-shot, HellaSwag 10-shot, HumanEval 0-shot, GSM8k CoT maj@1, and WinoGrande 5-shot.\n",
            "\n",
            "- **MT Bench**: Scores range from 8.05 to 9.03, with Mistral Large scoring the highest.\n",
            "- **MMLU 5-shot**: Scores range from 70.0% to 86.8%, with Claude 3 achieving the highest score.\n",
            "- **HellaSwag 10-shot**: Scores range from 84.7% to 95.4%, with Claude 3 again scoring the highest.\n",
            "- **HumanEval 0-shot (Programming)**: Scores range from 38.4% to 84.9%, with Gemini 1.5 Pro scoring the highest.\n",
            "- **GSM8k CoT maj@1 (5-shot)**: Scores range from 57.1% to 95.0%, with Claude 3 scoring the highest.\n",
            "- **WinoGrande 5-shot**: Scores range from 81.6% to 88.0%, with Mistral Large scoring the highest.\n",
            "\n",
            "The table indicates the quality of DBRX Instruct and other leading models, with most data sourced from the respective model creators' whitepapers, except for the Inflection Corrected MTBench, which was measured independently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3 - CSV Loader"
      ],
      "metadata": {
        "id": "xWHS0SnS-FZD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load doc & generate summary"
      ],
      "metadata": {
        "id": "_5zCeoHm-nLO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import CSVLoader\n",
        "\n",
        "loader = CSVLoader(file_path=\"/content/data.csv\")  # Upload file\n",
        "docs = loader.load()\n",
        "csv_text = \"\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that summarizes CSV data.\"),\n",
        "    (\"human\", \"Summarize the key insights from the following CSV data:\\n\\n{input_text}\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm\n",
        "response = chain.invoke({\"input_text\": csv_text})\n",
        "print(\"📊 CSV Summary:\\n\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d6R1bMQ-qhX",
        "outputId": "dab677ef-2679-42b7-bc71-9777ed56af60"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 CSV Summary:\n",
            " The CSV data contains sales transactions for various customers, all handled by Christy Zhu. The key insights from the data are as follows:\n",
            "\n",
            "1. **Product Details**: The primary product sold is the \"Mountain-100 Silver, 44\", with a consistent price of $3399.99 and a tax amount of $271.9992. Other products mentioned include \"Road-150 Red\", \"Mountain-100 Black\", and \"Road-650 Black/Red\", with varying sizes and prices.\n",
            "\n",
            "2. **Sales Dates**: The transactions span from July 1, 2019, to December 31, 2019. Each transaction is recorded with a specific sales order number (e.g., SO43701 to SO45265).\n",
            "\n",
            "3. **Customer Information**: Each transaction involves a different customer, identified by their name and email address. This suggests a diverse customer base with no repeat customers within the dataset.\n",
            "\n",
            "4. **Product Variations**: While the \"Mountain-100 Silver, 44\" is the most common product, there are variations in color and size for other products, such as \"Road-150 Red\" and \"Mountain-100 Black\", indicating a range of product offerings.\n",
            "\n",
            "5. **Pricing and Tax**: The pricing for the \"Mountain-100 Silver, 44\" remains constant, but other products like \"Road-650 Black/Red\" have significantly lower prices, around $699.0982, with corresponding lower tax amounts.\n",
            "\n",
            "6. **Email Domains**: All customer emails are from the \"adventure-works.com\" domain, indicating that this dataset might be internal or from a specific business context related to Adventure Works.\n",
            "\n",
            "Overall, the data reflects a structured sales process with a variety of products, consistent pricing for the main product, and a wide range of customers over a six-month period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4 - WebSite Loader"
      ],
      "metadata": {
        "id": "yyGjqffI-q-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Web-doc and generate summary"
      ],
      "metadata": {
        "id": "J9NxkPaz_Gc4"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "url = \"https://docs.databricks.com/aws/en/machine-learning/\"\n",
        "loader = WebBaseLoader(url)\n",
        "docs = loader.load()\n",
        "web_text = docs[0].page_content\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that summarizes web content.\"),\n",
        "    (\"human\", \"Summarize the following webpage content:\\n\\n{input_text}\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm\n",
        "response = chain.invoke({\"input_text\": web_text})\n",
        "print(\"🌐 Web Summary:\\n\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "571iKMer-6y9",
        "outputId": "b37040c2-d1be-4af0-95d9-a6ab3289438f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌐 Web Summary:\n",
            " The Databricks documentation on AI and machine learning provides an overview of how to build, deploy, and manage AI and machine learning applications using Mosaic AI, an integrated platform that supports the entire AI lifecycle from data preparation to production monitoring.\n",
            "\n",
            "Key features and tools include:\n",
            "\n",
            "1. **Generative AI Applications**: Develop enterprise-grade generative AI applications such as fine-tuned large language models (LLMs) and AI agents. Tools like AI Playground, Agent Bricks, and the Mosaic AI Agent Framework facilitate prototyping, building, and deploying these applications.\n",
            "\n",
            "2. **Classic Machine Learning Models**: Use automated tools and collaborative environments to create machine learning models. Features include AutoML for model building, Databricks Runtime for ML with pre-configured clusters, and MLflow for tracking and managing the model lifecycle.\n",
            "\n",
            "3. **Deep Learning Models**: Develop deep learning models using built-in frameworks like PyTorch and TensorFlow, with support for distributed training and best practices.\n",
            "\n",
            "4. **Model Deployment and Serving**: Deploy models to production with scalable endpoints and real-time inference. Features include Model Serving, AI Gateway for access governance, and integration of external models.\n",
            "\n",
            "5. **Monitoring and Governance**: Ensure model quality and compliance with tools like Unity Catalog for data governance, Lakehouse Monitoring for performance tracking, and MLflow for comprehensive monitoring.\n",
            "\n",
            "6. **Productionizing ML Workflows**: Scale operations with automated workflows, CI/CD integration, and production-ready pipelines. Features include Models in Unity Catalog for centralized governance, Lakeflow Jobs for ETL pipelines, and MLOps workflows for end-to-end operations.\n",
            "\n",
            "The documentation also highlights the importance of monitoring, governance, and scaling machine learning operations to ensure quality and compliance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End of the examples."
      ],
      "metadata": {
        "id": "nQzjDMvJ_EnV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqEqS2YW_O9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}